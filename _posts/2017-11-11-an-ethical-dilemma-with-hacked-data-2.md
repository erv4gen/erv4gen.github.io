---
layout: "post"
title: "An ethical dilemma with hacked data"
date: "2017-11-11 04:25:00 +0000"
author: "Vladimir"
wordpress_id: "9294"
status: "publish"
categories:
  - "blog"
---

<!-- Original WordPress Content (processed for shortcodes and media links) -->
<div dir="ltr" style="text-align: left;">
In <a href="https://rand-return.blogspot.com/2017/06/privacy-is-new-luxury.html">addition</a> to above-mention big data problem, I want to share with you one interesting <a href="/media/2016/10/Patreon-Case-Study.pdf">article</a>. In short, one company was trying to collect data for their research for a while and couldn't&nbsp;do&nbsp;it due to the technical complexity. But then some happened and database been hacked and published for everyone.&nbsp; The published dump has been contained a mix of private and public data itself.&nbsp; So, here is a dilemma: "Can this database dump now be used?", "Does it become "public"? or "whether to use this dataset to produce a socially useful research?"<br />
<br />
The bottom line is the company didn't use the hacked data. They provide the list of arguments which I share. Here is some:<br />
<br />
<ol style="text-align: left;">
<li>Researchers have a limited capability to distinguish between public and private information within the hacked data.&nbsp;</li>
<li>May see private data when cleaning the data.</li>
<li>Perhaps legitimizing criminal activity.&nbsp;</li>
<li>Violating users’ expectation of privacy.&nbsp;</li>
<li>Using people’s data without consent.&nbsp;</li>
<li>We want this data, but we don’t need it. Other data can be ethically collected and used</li>
</ol>
<div>
The only benefit of using the illegal information is a "faith in goodness powers of the research for men." But, honestly, it's a bull shit. The majority of research has a primary goal to increase the revenue of the company. The dirty pool game can break the fair concurrence in data-providers business. As a result, fewer companies&nbsp;will care about data security what can badly affect to the end user.</div>
<div>
<br />
<br /></div>
<div>
<br /></div>
<div>
<div style="clear: both; text-align: center;">
<a href="/media/2017/11/2017-11-10_22-03-06.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="631" data-original-width="1256" height="320" src="/media/2017/11/2017-11-10_22-03-06-300x151.png" width="640" /></a></div>
<div style="clear: both; text-align: center;">
Hack <a href="https://www.nytimes.com/2017/09/07/business/equifax-cyberattack.html">attack</a> on large credit company Equifax</div>
<br class="Apple-interchange-newline" />
In this case, the "black market of data" can occur. If a company needs some "sensitive" data for those research, they can just commission a hacking this data with the following publication. The company will wash hands of an affair shifting the blame on "a bad hacker." This kind of practice will finally remove borders in privacy.</div>
<div>
<br /></div>
<div>
Specialists of The University of Michigan comment:</div>
<div>
</div>
<div>
<div>
"When using the hacked data, you reward criminal activity, and in this&nbsp;way, criminals will be motivated to find more ways to hack data. It is like buying a stolen bike from a criminal. Besides, the private data can come in (more) wrong hands so the private data will be spread more and more among more and more people. And because researchers have a limited capability to distinguish between public and private information within the hacked data, they may use private data or spread private data by accident. All the above will lead to a higher&nbsp;possibility&nbsp;of abuse of private data."</div>
</div>
<div>
<br /></div>
<div>
<br /></div>
<div>
As a data science still a very young an against to journalism and don't have bases such as&nbsp;code of conduct, we need to be more careful in making decisions about what passes and what won't. It can be very complicated based on the fact that we can't evaluate an impact correctly for both cases. Let's say, we collect data for cancer&nbsp;research. For more performance, we need more information to mine. The results of our study would&nbsp;have a&nbsp;significant&nbsp;impact on&nbsp;man, sure enough. BUT, we can't calculate&nbsp;even closely the risk of concentration a massive amount of private, sensitive&nbsp;data in one place. If this kind of data would be used in bad faith, some the story can change unpredictably, and we faced the much worse questions.&nbsp;</div>
</div>